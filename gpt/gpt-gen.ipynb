{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONIOENCODING=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from src import sample, model, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_model(\n",
    "    model_name,\n",
    "    seed,\n",
    "    nsamples,\n",
    "    batch_size,\n",
    "    length,\n",
    "    temperature,\n",
    "    top_k,\n",
    "    models_dir\n",
    "):\n",
    "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "    assert nsamples % batch_size == 0\n",
    "\n",
    "    enc = encoder.get_encoder(model_name, models_dir)\n",
    "    hparams = model.default_hparams()\n",
    "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
    "        hparams.override_from_dict(json.load(f))\n",
    "\n",
    "    if length is None:\n",
    "        length = hparams.n_ctx // 2\n",
    "    elif length > hparams.n_ctx:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "        output = sample.sample_sequence(\n",
    "            hparams=hparams, length=length,\n",
    "            context=context,\n",
    "            batch_size=batch_size,\n",
    "            temperature=temperature, top_k=top_k\n",
    "        )\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "        while True:\n",
    "            raw_text = input(\"Model prompt >>> \")\n",
    "            while not raw_text:\n",
    "                print('Prompt should not be empty!')\n",
    "                raw_text = input(\"Model prompt >>> \")\n",
    "            context_tokens = enc.encode(raw_text)\n",
    "            generated = 0\n",
    "            for _ in range(nsamples // batch_size):\n",
    "                out = sess.run(output, feed_dict={\n",
    "                    context: [context_tokens for _ in range(batch_size)]\n",
    "                })[:, len(context_tokens):]\n",
    "                for i in range(batch_size):\n",
    "                    generated += 1\n",
    "                    text = enc.decode(out[i])\n",
    "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "                    print(text)\n",
    "            print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "INFO:tensorflow:Restoring parameters from models/1558M/model.ckpt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Model prompt >>>  The yawning black hole swallowed the entire Varian armada, leaving the human forces alone in the galaxy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== SAMPLE 1 ========================================\n",
      " In the ensuing battles, several Varian warships were destroyed, including Varian's starship, the Riptide. Although their captain escaped, only a fraction of their ships were salvaged, and all who survived the Riptide's destruction ended up as slaves in the Empire. In 2:32 BBY, the Dromund Kaas Imperial fleet retreated from the planet after they discovered that the Imperial Academy on Coruscant was a secret Star Wars training ground, although they did not learn of Varian's betrayal until the Imperial Academy burned to the ground, and no further action was taken.[2]\n",
      "\n",
      "The Human-Varian alliance Edit\n",
      "\n",
      "Shortly afterwards, the Varian fleet returned to its home system and was greeted by an enraged populace who had been kept in ignorance by the Empire of the Hand.[2] The Republic took advantage of this new threat in its quest for galactic power. The Galactic Senate's efforts to establish a new Republic military force by re-establishing the Jedi Order fell flat, and the Human-Varian alliance was formed.[11]\n",
      "\n",
      "The Alliance was initially composed of Varian's Free Companions, who were loyal to their new leader, as well as his former pupil and personal bodyguard, Tionne Solusar. In the early years of the Varian-Ardynous relationship, these two Sith Lords clashed regularly in battle, but they developed a close, and sometimes even violent, working relationship, as depicted in an\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Model prompt >>>  The yawning black hole swallowed the entire Varian armada, leaving the human forces alone in the galaxy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== SAMPLE 1 ========================================\n",
      " It had been years, after all, since the last enemy had been taken down.\n",
      "\n",
      "The other armadas of humanity were no less impressive – the Starfuries easily brought down several dozen smaller vessels, while the smaller strike craft, now dubbed Thunderwolves by the humans, were far more nimble with their massive weapons and speedier attack patterns.\n",
      "\n",
      "The humans were also far more numerous, so a new enemy was expected.\n",
      "\n",
      "One thousand two hundred ninety-seven ships made up the armada and they had been launched at different times and with different schedules. Some had even been launched from a hidden base on one of the planets of the Alliance – a massive mining operation that also contained a large array of warships.\n",
      "\n",
      "Some of the human battleship could carry dozens of pilots, which was useful, but more importantly the human ships were a highly trained and coordinated armada. The fleet had come together over thousands of years to become the most powerful in the galaxy.\n",
      "\n",
      "They had won their many battlefield victories in many different systems including at least four planets and three moons. In the space above the war the human fleets were being led by the elite squadrons of the Thunderwolves.\n",
      "\n",
      "In the end the Alliance forces, without the Varian fleet to bolster its ranks, would be overwhelmed and the alliance itself would be split in two and divided.\n",
      "\n",
      "\"I never thought you'd join us\", said Lord Faren.\n",
      "\n",
      "\"I've been wondering,\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Model prompt >>>  \"Mom...\" she whined, \"this is ridiculous!\"\n"
     ]
    }
   ],
   "source": [
    "interact_model(\n",
    "    model_name = '1558M',\n",
    "    seed = None,\n",
    "    nsamples = 1,\n",
    "    batch_size = 1,\n",
    "    length = 300,\n",
    "    temperature = 1,\n",
    "    top_k = 40,\n",
    "    models_dir = 'models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
